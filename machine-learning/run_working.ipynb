{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5db023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb96061b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n~~~~~~~~~~~ Start of Quantum Machine Learning Script! ~~~~~~~~~~~\\n\\nIdeas/Improvements:\\n- This model uses direct eigenvectors of the Hamiltonian for training data. Instead, it\\nis possible to use optimized angles of each nuclear configuration instead, and generate\\na state_vector out of this (which is entirely supported by Pennylane) for training data.\\nHowever, this requires the Adapt-VQE gate selection protocol to be run first to select\\nall necessary quantum gates so all training data wavefunctions have the same number of\\ngate parameters\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "~~~~~~~~~~~ Start of Quantum Machine Learning Script ~~~~~~~~~~~\n",
    "\n",
    "Ideas/Improvements:\n",
    "- This model uses direct eigenvectors of the Hamiltonian for training data. Instead, it\n",
    "is possible to use optimized angles of each nuclear configuration instead, and generate\n",
    "a state_vector out of this (which is entirely supported by Pennylane) for training data.\n",
    "However, this requires the Adapt-VQE gate selection protocol to be run first to select\n",
    "all necessary quantum gates so all training data wavefunctions have the same number of\n",
    "gate parameters\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f210c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported Dependencies!\n"
     ]
    }
   ],
   "source": [
    "# Imports and Relevant Defines:\n",
    "\n",
    "# Jax needs more precision to calculate quantum data,\n",
    "# so ensure the environment variable is set before importing JAX\n",
    "import os\n",
    "os.environ['JAX_ENABLE_X64'] = 'True'\n",
    "\n",
    "#import autohf as hf\n",
    "import pennylane.numpy as np\n",
    "import pennylane as qml\n",
    "import jax\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "# import tailgating as tg\n",
    "import scipy as sc\n",
    "import optax # is a gradient-processing library for jax\n",
    "from pennylane import qchem\n",
    "import sys\n",
    "from data import *\n",
    "from nn import *\n",
    "from utils import *\n",
    "from vqe import *\n",
    "print(\"Successfully imported Dependencies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfb96ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main Script functions:\n",
    "\n",
    "import math\n",
    "\n",
    "def R_from_axis_angle(axis, angle):\n",
    "    \"\"\" Find the rotation matrix R(K, theta) \n",
    "        @param axis (K): axis of rotation and \n",
    "        @param theta: rotation angle in degrees\n",
    "        @return R: rotation matrix (3x3 numpy array)\n",
    "    \"\"\"\n",
    "    sina = math.sin(angle * np.pi/180) # convert to radians\n",
    "    cosa = math.cos(angle * np.pi/180) # convert to radians\n",
    "    axis = unit_vector(axis[:3])\n",
    "    kx = axis[0]; ky = axis[1]; kz = axis[2]\n",
    "    # rotation matrix around unit vector\n",
    "    \n",
    "    R = np.array([\n",
    "                [(kx**2)*(1-cosa) + cosa, kx*ky*(1-cosa)-kz*sina, kx*kz*(1-cosa)+ky*sina],\n",
    "                [kx*ky*(1-cosa)+kz*sina, (ky**2)*(1-cosa) + cosa, ky*kz*(1-cosa)-kx*sina],\n",
    "                [kx*kz*(1-cosa)-ky*sina, ky*kz*(1-cosa)+kx*sina, (kz**2)*(1-cosa) + cosa]\n",
    "                ])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def rotate_and_translate_water(x, axis, angle, transl_vec):\n",
    "    rotation_matrix = R_from_axis_angle(axis, angle)\n",
    "    new_x = np.array([0.0, 0.0, 0.0,0.0, 0.0, 0.0,0.0, 0.0, 0.0], requires_grad=True)\n",
    "    \n",
    "    # Rotate each vertex\n",
    "    point1 = x[0:3]\n",
    "    point1_rot = np.dot(rotation_matrix, point1) # Ordering matters. First rotate, then translate.\n",
    "    point1_rot += transl_vec\n",
    "    new_x[0:3] = point1_rot\n",
    "    \n",
    "    point2 = x[3:6]\n",
    "    point2_rot = np.dot(rotation_matrix, point2)\n",
    "    point2_rot += transl_vec\n",
    "    new_x[3:6] = point2_rot\n",
    "    \n",
    "    point3 = x[6:9]\n",
    "    point3_rot = np.dot(rotation_matrix, point3)\n",
    "    point3_rot += transl_vec\n",
    "    new_x[6:9] = point3_rot\n",
    "    \n",
    "    return new_x\n",
    "\n",
    "# Factor to convert from Bohrs to Angstroms\n",
    "bohr_angs = 0.529177210903\n",
    "\n",
    "def build_xyz(r, angle): # prepares an equilateral triagnle's coordinates of H3+!\n",
    "    r = r/bohr_angs\n",
    "    x = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    # O at (0,0,0)\n",
    "    x[0] = 0.0\n",
    "    x[1] = 0.0\n",
    "    x[2] = 0.0\n",
    "    \n",
    "    # H1 at (r*cos(angle),r*sin(angle),0)\n",
    "    x[3] = r * np.cos(angle * np.pi/180)\n",
    "    x[4] = r * np.sin(angle * np.pi/180)\n",
    "    x[5] = 0.0\n",
    "    \n",
    "    # H2 at (r, 0, 0)\n",
    "    x[6] = r\n",
    "    x[7] = 0.0\n",
    "    x[8] = 0.0\n",
    "    \n",
    "    # rotate water:\n",
    "    new_x = rotate_and_translate_water(x, axis, rot_angle, transl_vec)\n",
    "    \n",
    "    return new_x\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2':\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return (np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)) * 180/math.pi) #convert to degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "945c4c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in Neural Network Parameters:\n",
    "\n",
    "nn_layers = [40, 40]\n",
    "optimizer = optax.adam(0.01)\n",
    "n_steps = 4000 # original code used 2000\n",
    "n_params = 2 # number of z-matrix parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85abd15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in molecule data:\n",
    "\n",
    "symbols = [\"O\", \"H\", \"H\"]\n",
    "charge = 0\n",
    "active_electrons = 8\n",
    "active_orbitals = 6\n",
    "\n",
    "# Default rotation and translation parameters of molecule in 3D-Space:\n",
    "axis = np.array([1, -5, 13]) # any set of numbers, bc it will be normalized to unit vector\n",
    "rot_angle = 114 # in degrees\n",
    "transl_vec = np.array([0.0000,0.7581,-0.5086]) # keep in atomic units\n",
    "\n",
    "\n",
    "# Other stats:\n",
    "wires = active_orbitals * 2 # assumes the STO-3G basis, b/c only works for the Jordan-Wigner mapping\n",
    "\n",
    "# Making a sparse Hamiltonian:\n",
    "def H_sparse(r, theta):\n",
    "    global symbols, charge,  active_electrons, active_orbitals, wires # import in global variables\n",
    "    Hamiltonian = qml.qchem.molecular_hamiltonian(symbols, build_xyz(r, theta), charge=charge,\n",
    "                                                  active_electrons = active_electrons,\n",
    "                                                  active_orbitals = active_orbitals\n",
    "                                                 )[0]  \n",
    "    return qml.SparseHamiltonian(Hamiltonian.sparse_matrix(), wires=range(wires))\n",
    "\n",
    "# r_train, theta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d17f010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate training z-matrix parameters:\n",
    "\n",
    "'''\n",
    "IMPORTANT:\n",
    "\n",
    "Make array or not array decision when which form inputs are fed into\n",
    "jax.numpy() neural networks, which are implemented as jax.numpy (jnp)\n",
    "matrix and arrays\n",
    "'''\n",
    "\n",
    "N_train = 3\n",
    "# Enter all radial lengths in units of angstroms\n",
    "# Originally: r_train = [[x] for x in np.linspace(0.2, 2.0, N_train)]\n",
    "r_train = [x for x in np.linspace(0.2, 2.0, N_train)]\n",
    "\n",
    "# Enter all angular widths in units of degrees\n",
    "# Originally: theta_train = [[x] for x in np.linspace(60, 130, N_train)]\n",
    "theta_train = [x for x in np.linspace(60, 130, N_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7054f603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def exact_diag_data_sparse(H, samples, weight, spin, k=None): # g stands for geometry, s stands for state\n",
    "#     \"\"\"Generates data with exact diagonalization of the Hamiltonian (assumes the generated Hamiltonian is sparse)\"\"\"\n",
    "#     training_g, training_s = [], []\n",
    "#     for r in tqdm(samples):\n",
    "#         h = H(r).sparse_matrix()\n",
    "#         k = 6 if k is None else k\n",
    "#         v, w = allowed_vec_val_sparse(h, weight, spin, k=k) # 'allowed_vec_val_sparse' is in line 125 above\n",
    "#         # allowed_vec_val_sparse() returns v(list of eigenvectors) and w(list of eigenvalues) that\n",
    "        \n",
    "#         min_index = np.where(w == min(w)) # in list of all eigenstates + corresponding eigenvalues, return index of lowest eigenvalue\n",
    "#         training_g.append(jnp.array(r)) # append the param \"r\" that we're shifting by to create sample\n",
    "#         training_s.append(jnp.array(v.T[min_index][0])) # append ground state of Hamiltonian (eigenvector of H-matrix)\n",
    "#     return jnp.array(training_g), jnp.array(training_s)\n",
    "\n",
    "# g_data, s_data = exact_diag_data_sparse(H_sparse, samples, mol.active_electrons, 0)\n",
    "\n",
    "def exact_diag_data_sparse(H, r_train, theta_train, weight, spin, k=None): # g stands for geometry, s stands for state\n",
    "    \"\"\"Generates data with exact diagonalization of the Hamiltonian (assumes the generated Hamiltonian is sparse)\"\"\"\n",
    "    training_w, training_s = [], []\n",
    "    for r, theta in zip(r_train, theta_train):\n",
    "        h = H(r,theta).sparse_matrix()\n",
    "        k = 6 if k is None else k\n",
    "        v, w = allowed_vec_val_sparse(h, weight, spin, k=k) # 'allowed_vec_val_sparse' is in line 125 above\n",
    "        # allowed_vec_val_sparse() returns v(list of eigenvectors) and w(list of eigenvalues) that\n",
    "        \n",
    "        min_index = np.where(w == min(w)) # in list of all eigenstates + corresponding eigenvalues, return index of lowest eigenvalue\n",
    "        training_w.append(jnp.array(w[min_index])) # append the param \"r\" that we're shifting by to create sample\n",
    "        training_s.append(jnp.array(v.T[min_index][0])) # append ground state of Hamiltonian (eigenvector of H-matrix)\n",
    "    return jnp.array(training_w), jnp.array(training_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026cafa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# Generate training quantum wavefunctions:\n",
    "'''\n",
    "Notes:\n",
    "-> Extract eigenvalues which original function doesn't do, and see if it looks correct\n",
    "Done, Checked for water's values, and it does! Now we know that the generated training wavefunctions\n",
    "are correct for each pair of z-matrix parameters\n",
    "\n",
    "->Test out ordering of sparse-matrix:\n",
    "Done, Saw that it mattered, keep in same ordering as function, because we have to convert it back to an array\n",
    "'''\n",
    "# for me: reference extract_data() and in it, coupe lines down of model_energy() call in main script at the very\n",
    "# beginning to see how they check the ground-state eigenvalue -> check these values for this training data by\n",
    "# plotting it out!\n",
    "\n",
    "# Test out ordering of sparse-matrix\n",
    "\n",
    "eigenval_train, eigenvec_train = exact_diag_data_sparse(H_sparse, r_train, theta_train, active_electrons, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a26a3792",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-55.22178269],\n",
       "       [-75.01607097],\n",
       "       [-74.75956212]], dtype=float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenval_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f245ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def gate_pool(mol, sz=0):\n",
    "#     \"\"\"Generates a gate pool and single and double excitations\"\"\"\n",
    "#     singles, doubles = qml.qchem.excitations(electrons=mol.active_electrons, orbitals=2 * mol.active_orbitals, delta_sz=sz)\n",
    "#     # This comment is confirming this function is still updated -> delta_sz is an actual parameter of the updated function!\n",
    "#     # Delta-sz specifies the selection rule\n",
    "    \n",
    "#     pool1, pool2 = [], []\n",
    "    \n",
    "#     # here, we are appending lambda functions\n",
    "#     for s in singles:\n",
    "#         pool1.append(lambda p, w=s: qml.SingleExcitation(p, wires=w))\n",
    "#     for d in doubles:\n",
    "#         pool2.append(lambda p, w=d: qml.DoubleExcitation(p, wires=w))\n",
    "        \n",
    "#         # return pool2, or doubles gates, first in the tuple, because we do adapt-vqe on these gates first!\n",
    "#     return pool2, pool1\n",
    "\n",
    "def gate_pool(active_electrons, active_orbitals, sz=0):\n",
    "    \"\"\"Generates a gate pool and single and double excitations\"\"\"\n",
    "    singles, doubles = qml.qchem.excitations(electrons=active_electrons, orbitals=2 * active_orbitals, delta_sz=sz)\n",
    "    # This comment is confirming this function is still updated -> delta_sz is an actual parameter of the updated function!\n",
    "    # Delta-sz specifies the selection rule\n",
    "    \n",
    "    pool1, pool2 = [], []\n",
    "    \n",
    "    # here, we are appending lambda functions\n",
    "    for s in singles:\n",
    "        pool1.append(lambda p, w=s: qml.SingleExcitation(p, wires=w))\n",
    "    for d in doubles:\n",
    "        pool2.append(lambda p, w=d: qml.DoubleExcitation(p, wires=w))\n",
    "        \n",
    "        # return pool2, or doubles gates, first in the tuple, because we do adapt-vqe on these gates first!\n",
    "    return pool2, pool1\n",
    "\n",
    "\n",
    "# def generate_hf_state(molecule):\n",
    "#     \"\"\"Returns the HF state for a molecule\"\"\"\n",
    "#     return qchem.hf_state(molecule.active_electrons, 2 * molecule.active_orbitals)\n",
    "\n",
    "def generate_hf_state(active_electrons, active_orbitals):\n",
    "    \"\"\"Returns the HF state for a molecule\"\"\"\n",
    "    return qchem.hf_state(active_electrons, 2 * active_orbitals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc59f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conduct Adapt-VQE procedure for selecting relevant quantum gates in training data:\n",
    "\n",
    "# Initializes an optimizer for the adaptive procedure\n",
    "optimizer = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "# Initialize device to also run procedure:\n",
    "dev = qml.device(\"default.qubit\", wires = 2*active_orbitals)\n",
    "# Define number of steps for optimizing double excitation gates:\n",
    "num_steps = 20\n",
    "# variable for wires (used in later code):\n",
    "wires = 2*active_orbitals\n",
    "\n",
    "# return all possible single and double excitation gates with a molecule of this size active space:\n",
    "pool = gate_pool(active_electrons, active_orbitals)\n",
    "\n",
    "# now, perform Adapt-VQE gate selection algorithm for all possible training z-matrix geometries:\n",
    "gates = []\n",
    "for r, theta in zip(r_train, theta_train):\n",
    "    H_hf = H_sparse(r, theta)\n",
    "    gates_t, params = batch_adapt_vqe(H_hf, dev, pool,\n",
    "                                      generate_hf_state(active_electrons, active_orbitals),\n",
    "                                      optimizer, num_steps, # generate_hf_state() is found in data.py, line 215.    \n",
    "                                      bar=False, sparse=True, tol=1e-5)\n",
    "    gates.extend(gates_t) # add all gates for each geometry\n",
    "gates = list(set(gates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce039d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa2b78bc-5e29-466d-a053-ed6d2677cf16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circuit(gates, wires, initial):\n",
    "    \"\"\"Circuit for generating data\"\"\"\n",
    "    def data_generating_circuit(params):\n",
    "        qml.BasisState(initial, wires=range(wires)) # change is re-define this to be range(wires)\n",
    "        for p, g in zip(params, gates):\n",
    "            g(p)\n",
    "    return data_generating_circuit\n",
    "\n",
    "def state_circuit(circ, dev):\n",
    "    \"\"\"State generating circuit\"\"\"\n",
    "    @qml.qnode(dev, interface=\"jax\") # impotant to have the interface be \"jax\"?\n",
    "    def state_circ(params):\n",
    "        circ(params)\n",
    "        return qml.state()\n",
    "    return state_circ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdb1aa14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions to return full quantum-state of mplecule based on gate parameters:\n",
    "\n",
    "# cicuit() returns a circuit lambda function. All we have to do is provide parameters and this creates\n",
    "# quantum-circuit with parameters applied to selected gates. This circuit is passed into next function, state_circuit()\n",
    "circ = circuit(gates, wires, generate_hf_state(active_electrons, active_orbitals)) # Circuit ansatz. 'circuit()' is from vqe.py, line 238\n",
    "\n",
    "# state_circuit() uses above circuit, and makes a qnode out of it with a device, and actually returns a quantum state.\n",
    "# same thing, tho. In the return of this function, so \"state_circ\", just pass in parameters of gates and out comes\n",
    "# a quantum state!\n",
    "# To note is that the interface should be \"jax\", ig for optimization of the nn later in the code?\n",
    "state_circ = state_circuit(circ, dev) # State-generating circuit: 'state_circuit' function pulled it from vqe.py, line 246\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ecab1099-b695-45ea-852d-834ffa7d0739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def exact_fidelity_loss(model, x, y): # x=g_data (vector of geometry inputs), y=s_data (vector of corresponding target quantum states)\n",
    "#     \"\"\"\n",
    "#     Exact fidelity loss function for a given neural network (this function's return type will\n",
    "#     accept different neural network parameters, NN)\n",
    "    \n",
    "#     Imran's Note: NN are the neural network parameters\n",
    "#     \"\"\"\n",
    "#     def fn(NN): # from the code in \"run.py\" we can tell that \"NN\" is the initial neural network parameters, or \"initial_NN_params\"\n",
    "#         samples = len(x)\n",
    "#         return jnp.real((1/samples) * jnp.sum(batch_exact_fidelity_loss(model)(NN, x, y))) # jnp.sum will sum up the \"1-\" in \n",
    "#             # exact_fidelity_loss_sample to be \"N -\", but the \"1/samples\" in this function returns it to the \"1\" we see in the\n",
    "#             # official formula for the cost function!\n",
    "#     return fn\n",
    "\n",
    "def exact_fidelity_loss(model, x, y): # x=g_data (vector of geometry inputs), y=s_data (vector of corresponding target quantum states)\n",
    "    \"\"\"\n",
    "    Exact fidelity loss function for a given neural network (this function's return type will\n",
    "    accept different neural network parameters, NN)\n",
    "    \n",
    "    Imran's Note: NN are the neural network parameters\n",
    "    \"\"\"\n",
    "    def fn(NN): # from the code in \"run.py\" we can tell that \"NN\" is the initial neural network parameters, or \"initial_NN_params\"\n",
    "        samples = len(x)\n",
    "        return jnp.real((1/samples) * jnp.sum(jnp.array([exact_fidelity_loss_sample(model)(NN, g, s) for g, s in zip(x, y)]))) \n",
    "            # exact_fidelity_loss_sample to be \"N -\", but the \"1/samples\" in this function returns it to the \"1\" we see in the\n",
    "            # official formula for the cost function!\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "792d525b-76fd-4eaf-b0d1-2ba1cbd743ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.34616549, dtype=float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_fidelity_loss(model, g_data, s_data)(initial_NN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a49dad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, set up functions to begin training neural network!!\n",
    "\n",
    "# re-shape all z-matrix arrays into an array of jnp-arrays -> call g_data:\n",
    "g_data = []\n",
    "for r, theta in zip(r_train, theta_train):\n",
    "    g_data.append(jnp.array([r, theta]))\n",
    "   \n",
    "# define s-data is array of eigenvectors from earlier:\n",
    "s_data = eigenvec_train\n",
    "    \n",
    "# re-define device according to Pennylane documentation on how to work with Jax interface:\n",
    "dev = qml.device(\"default.qubit.jax\", wires = 2*active_orbitals)\n",
    "\n",
    "# jax key to initialize neural network values (uses jax framework also)\n",
    "key = jax.random.PRNGKey(100)\n",
    "\n",
    "# Specifies the sizes of each of the layers in the feed-forward NN\n",
    "layer_sizes = [n_params] + nn_layers + [len(gates)]\n",
    "\n",
    "# Specifies the initial NN params (all set to 0.0)\n",
    "initial_NN_params = network_params(layer_sizes, key, zero=True) # initial_NN_params is an array of tuples, holding the Matrix/Vector values of each layer for all neuron weights and biases   \n",
    "\n",
    "# Quantum model\n",
    "def model(geometry, NN_theta): # NN_theta is an array of tuples, storing (W,b). W is a matrix of weights, and b is a vector of biases\n",
    "    angles = neural_network(NN_theta, geometry)\n",
    "    return state_circ(angles)\n",
    "\n",
    "optimizer = optax.adam(0.01) # re-define optimizer variable to be the optax one that will train on the neural network!\n",
    "params = {'w': initial_NN_params}\n",
    "opt_state = optimizer.init(params) # from documentaton -> initialize optimizer with the parameters of the nn you want to join\n",
    "\n",
    "# Loss function\n",
    "loss = lambda NN : exact_fidelity_loss(model, g_data, s_data)(NN['w']) # notice 'NN' into this function. Later, we see it's passed as 'params'\n",
    "\n",
    "# Gradient of loss function\n",
    "gradient_fn = jax.jit(jax.value_and_grad(loss))\n",
    "\n",
    "# finally, initialize amount of forward and backward passes of the neural network\n",
    "steps = n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "725103e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf0aad8660c480aa55afd73157bb474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss = 0.34616549023591525\n",
      "Initial loss = 0.34616549023591525\n",
      "Final loss = 0.24187184796948097\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network.\n",
    "\n",
    "bar = tqdm(range(steps))\n",
    "print(\"Initial loss = {}\".format(loss(params))) \n",
    "\n",
    "# Performs optimization of the model\n",
    "for s in bar:\n",
    "    v, gr = gradient_fn(params) # returns v, which is value, and gr, which is gradient.\n",
    "    bar.set_description(str(v))\n",
    "\n",
    "    # Computes the gradient, updates the parameters\n",
    "    updates, opt_state = optimizer.update(gr, opt_state) # opt_state is the state of the optimizer. updates is the actual updates of the NN params!\n",
    "    params = optax.apply_updates(params, updates) # what optax updates and returns to you is the updated dictionary that * holds* the parameters?\n",
    "\n",
    "print(\"Final loss = {}\".format(loss(params))) \n",
    "\n",
    "# Optimized model\n",
    "optimized_model = lambda g : model(g, params['w'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ab4f4cf-fdc8-4170-89ee-77438d48130a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-74.9476520763531"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing out the neural network:\n",
    "\n",
    "r = 1.01\n",
    "theta = 104.5\n",
    "\n",
    "test_sample = jnp.array([r, theta])\n",
    "H_test = H_sparse(r, theta)\n",
    "model_val = optimized_model(test_sample)\n",
    "m =  np.real(np.dot(np.conj(model_val), H_test.sparse_matrix() @ model_val))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83cb5707-a303-4272-8eb4-68ff995113da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-matrix params for Water: 1.01 and 90.0\n",
      "Energy Eigenvalue: -74.91459638368569 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 91.0\n",
      "Energy Eigenvalue: -74.91802765494346 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 92.0\n",
      "Energy Eigenvalue: -74.92128072456106 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 93.0\n",
      "Energy Eigenvalue: -74.92435742134862 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 94.0\n",
      "Energy Eigenvalue: -74.92725956606647 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 95.0\n",
      "Energy Eigenvalue: -74.9299889747712 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 96.0\n",
      "Energy Eigenvalue: -74.93254746190526 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 97.0\n",
      "Energy Eigenvalue: -74.93493684316674 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 98.0\n",
      "Energy Eigenvalue: -74.93715893817529 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 99.0\n",
      "Energy Eigenvalue: -74.9392155729653 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 100.0\n",
      "Energy Eigenvalue: -74.94110858231805 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 101.0\n",
      "Energy Eigenvalue: -74.94283981195764 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 102.0\n",
      "Energy Eigenvalue: -74.94441112062688 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 103.0\n",
      "Energy Eigenvalue: -74.94582438205434 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 104.0\n",
      "Energy Eigenvalue: -74.94708148683638 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 105.0\n",
      "Energy Eigenvalue: -74.94818434423732 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 106.0\n",
      "Energy Eigenvalue: -74.94913488393344 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 107.0\n",
      "Energy Eigenvalue: -74.94993505770356 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 108.0\n",
      "Energy Eigenvalue: -74.95058684100354 Ha\n",
      "\n",
      "Z-matrix params for Water: 1.01 and 109.0\n",
      "Energy Eigenvalue: -74.95109223491582 Ha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta_arr = []\n",
    "m_arr = []\n",
    "\n",
    "theta_base = 90.0\n",
    "for i in range(20):\n",
    "    theta = theta_base+i\n",
    "    test_sample = jnp.array([r, theta])\n",
    "    H_test = H_sparse(r, theta)\n",
    "    model_val = optimized_model(test_sample)\n",
    "    m =  np.real(np.dot(np.conj(model_val), H_test.sparse_matrix() @ model_val))\n",
    "    print(\"Z-matrix params for Water:\", r, \"and\", theta)\n",
    "    print(\"Energy Eigenvalue:\", m, \"Ha\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bd858-ed8f-4652-85ae-331a022de206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum_ML",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
